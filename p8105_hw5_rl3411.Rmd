---
title: "p8105_hw5_rl3411"
author: "rl3411"
date: "2023-11-09"
output: github_document
---

```{r, message = F}
library(tidyverse)
library(purrr)

knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    fig.width = 8, 
  fig.height = 6,
  out.width = "100%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

```{r}
hom_data = read_csv("data/homicide-data.csv") |> 
  mutate(city_state = paste(city, state, sep =", ")) 
```

This dataset contains 52,179 criminal homicides from 2007 to 2017 in 50 American cities. It includes the date, location of the killing (latitude, longitude, city and state of the killing), demographic information about each victim (first and last name, race, age, sex) and the disposition of each record.

```{r}
disp_df = hom_data |> 
  group_by(city_state) |> 
  summarize(total_homicides = n(),
            unsolved = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest"))
```

```{r}
balt_prop = disp_df |> 
  filter(city_state == "Baltimore, MD") 

test = 
  prop.test(x = balt_prop$unsolved, n = balt_prop$total_homicides) |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high)
head(test)
```

```{r}
result = disp_df |> 
  mutate(test_result = map2(unsolved, total_homicides, prop.test)) |> 
  mutate(test_result = map(test_result, broom::tidy)) |> 
  unnest(test_result) |> 
  select(city_state, estimate, conf.low, conf.high) 

knitr::kable(result)
```
```{r}
result |>  
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = estimate, y = city_state)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + 
  labs (title = "Proportion of unsolved homicides in each city",
        x = "Proportion",
        y = "City")
```


# Problem 2

### Create and tidy dataset

```{r, message = F}
study = 
  tibble(file_name = list.files(path = "data", 
                                pattern = "^[a-z]{3}_\\d{2}\\.csv$", 
                                full.names = TRUE)) |> 
  mutate(value = map(file_name, read_csv)) |> 
  unnest(value) |> 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "obs"
  ) |> 
  mutate(week = str_sub(week, 6, 6),
         file_name = str_sub(file_name, 6, 11),
         file_name = str_replace_all(file_name, c("con"= "control", "exp" = "experimental"))) |> 
  rename(arm_ID = file_name)
```

### Spaghetti plot: observations on each subject over time

```{r, message = F}
study |> 
  mutate(arm = case_when(
    str_detect(arm_ID, "^control") ~ "control",
    str_detect(arm_ID, "^experimental") ~ "experimental")) |> 
  ggplot(aes(x = week, y = obs, group = arm_ID, color = arm_ID)) + 
  geom_line() +
  geom_smooth(aes(group = arm, color = factor(arm)), se = F) +
  labs(title = "Observations on each subject over 8 weeks")
```

From this plot, we can see that the observational values for subjects in the experimental arm increases through the 8-week period while those in the control arm remain around 1.2 units. This suggests that the treatment/intervention might be causing an effect, resulting in higher values among the experimental group.

# Problem 3
h
### Generating dataset of samples

```{r}
set.seed(828)

mu_sample = function(mu, n = 30, sd = 5){
  x_vec = rnorm(n = n, mean = mu, sd = sd)
  sim_result = t.test(x_vec, mu = 0, alternative = "two.sided", conf.level = 0.95) |> 
    broom::tidy() |> 
    select(estimate, p.value)
}

sim_result_df = 
  expand_grid(
    mu = c(0,1,2,3,4,5,6),
    iter = 1:5000
  ) |> 
  mutate(estimate_df = map(mu, mu_sample)) |> 
  unnest(estimate_df) |> 
  mutate(power = p.value < 0.05)
```

### Investigating the power of the test

```{r}
sim_result_df |>  
  group_by(mu) |>  
  summarize(prop = mean(power)) |> 
  ggplot(aes(x = factor(mu), y = prop)) +
  geom_bar(stat = "identity") +
  labs(title = "Proportion of times the null was rejected for each mu",
       x = "mu",
       y = "Power")
```

From this plot, we can see that the power increases as the true value of $\mu$ increases, i.e. power increases as effect size increases.

### How does the average estimate of $\hat{\mu}$ for all data differ from those that rejected the null?

```{r}
avg_estimate = sim_result_df |>  
  group_by(mu) |>  
  summarize(mean_muhat = mean(estimate)) |> 
  mutate(data = "all")

overlay_data = sim_result_df |> 
  filter(power == TRUE) |> 
  select(mu, estimate) |> 
  group_by(mu) |>  
  summarize(mean_muhat = mean(estimate)) |> 
  mutate(data = "null rejected")

graph_df = bind_rows(avg_estimate, overlay_data)

graph_df |> 
  ggplot(aes(x = mu, y = mean_muhat, color = data)) +
  geom_line() +
  geom_point() +
  geom_text(aes(label=round(mean_muhat,1)), 
            vjust = -2,  
            size=3) +
  scale_x_discrete(limits = seq(0,6,1)) +
  scale_y_discrete(limits = seq(0,6,1)) +
  labs(title = "All data vs rejected null",
       x = "true mu",
       y = "Average estimate of mu hat")
```

Here, we can see that the average estimate of $\hat{\mu}$ for the rejected null data **deviates** from all data, for smaller values of the true $\mu$. But as the true $\mu$ increases, the difference gets smaller and the sample average of $\hat{\mu}$ starts to be approximately equal to the true value of $\mu$ starting $\mu=4$. The reason behind this is because for smaller $\mu$, there would be more estimates closer to 0, meaning that only the estimates that are further away from 0 will have the null hypothesis rejected. As the true value for $\mu$ increases, we would expect all or almost all samples to have $\hat{\mu}$ significantly different from 0.





